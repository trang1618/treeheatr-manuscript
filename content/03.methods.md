## Methods

We utilize the *ggparty* R package to compute the conditional inference tree (indirectly via the *partykit* R package) and edge and node information.
However, because *ggparty* assumes fixed terminal widths, we recompute the node layout to accommodate the different number of samples shown in the heatmap at each terminal node.
We implemented a node layout structure that can generalize as the trees grow in size.
This new layout weighs the *x*-coordinate of the parent node according to the level of the child nodes in order to avoid crossing of tree branches.
This relative weight can be adjusted with the lev_fac parameter in `heat_tree()`.
`lev_fac = 1` sets the parent node's *x*-coordinate perfectly in the middle of those of its child nodes.
The default `lev_fac = 1.3` seems to provide aesthetically pleasing trees independent of the tree size (see [vignette](https://trang1618.github.io/treeheatr/articles/explore.html)).

As default, *treeheatr* automatically performs clustering when organizing the heatmap.
To order the features, clustering is run on the two groups of features, continuous and categorical, across all samples (including the outcome label, unless `clust_target = FALSE`).
To order the samples, clustering is run on samples within each terminal node of all features. 
*treeheatr* uses [`cluster::daisy()`](https://cran.r-project.org/web/packages/cluster/) with the Gower metric [@doi:10.2307/2528823] to incorporate both continuous and nominal categorical feature types. 

In a visualization, it is difficult to find the balance between enhancing understanding and overloading information.
We left it for the user to decide what type of information they want to show at inner nodes via different *geom* objects in the *ggparty* package.
We believe displaying a heatmap at the terminal node space 

This visualization nicely complements the current techniques of visualizing decision trees.
Node purity, a metric measuring the tree's performance, can be visualized from the distribution of true outcome label at each terminal node in the first row.
Comparing these values with the terminal node label gives a visual estimate of how accurate the tree predictions are.
Without specifically choose two features to show in a 2-D scatter plot, we can infer correlation structures among features in the heatmap.
The additional clustering also helps with the interpretation of the [...]
